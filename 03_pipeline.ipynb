{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from llama_index.core import Settings\n",
    "from llama_index.llms.groq import Groq\n",
    "import dotenv\n",
    "\n",
    "dotenv.load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "Settings.llm = Groq(model=\"llama3-70b-8192\",\n",
    "                    api_key=os.getenv(\"groqKey\"))\n",
    "import pandas as pd\n",
    "\n",
    "df_vendas = pd.read_csv(\"vendas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "from llama_index.experimental.query_engine.pandas import PandasInstructionParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "instruction_str = (\n",
    "    \"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
    "    \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
    "    \"3. O código deve representar uma solução para a consulta.\\n\"\n",
    "    \"4. IMPRIMA APENAS A EXPRESSÃO.\\n\"\n",
    "    \"5. Não coloque a expressão entre aspas.\\n\")\n",
    "\n",
    "# Prompt que será enviado ao modelo para que ela gere o código Pandas desejado\n",
    "pandas_prompt_str = (\n",
    "    \"Você está trabalhando com um dataframe do pandas em Python chamado `df_vendas`.\\n\"\n",
    "    \"{colunas_detalhes}\\n\\n\"\n",
    "    \"Este é o resultado de `print(df_vendas.head())`:\\n\"\n",
    "    \"{df_str}\\n\\n\"\n",
    "    \"Siga estas instruções:\\n\"\n",
    "    \"{instruction_str}\\n\"\n",
    "    \"Consulta: {query_str}\\n\\n\"\n",
    "    \"Expressão:\"\n",
    ")\n",
    "\n",
    "# Prompt para guiar o modelo a sintetizar uma resposta com base nos resultados obtidos pela consulta Pandas\n",
    "response_synthesis_prompt_str = (\n",
    "   \"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
    "   \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
    "   \"Consulta: {query_str}\\n\\n\"\n",
    "   \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
    "   \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
    "   \"Resposta:\"\n",
    "   \"Ao final, exibir o código usado para gerar a resposta, no formato: O código utilizado foi {pandas_instructions}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def descreve_colunas(df):\n",
    "    descricao = \"\\n\".join([f\"{col}: {str(df[col].dtype)}\"for col in df.columns])\n",
    "    return \"detalhes da colunas do dataframe:\\n\" , descricao"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str,colunas_detalhes=descreve_colunas(df_vendas),df_str=df_vendas.head(5)\n",
    ")\n",
    "\n",
    "pandas_output_parser = PandasInstructionParser(df_vendas)\n",
    "\n",
    "response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "\n",
    "\n",
    "llm = Groq(model=\"llama3-70b-8192\",api_key=os.getenv(\"groqKey\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.query_pipeline import (QueryPipeline as QP,Link,InputComponent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp = QP(\n",
    "    modules={\n",
    "        \"input\":InputComponent(),\n",
    "        \"pandas_prompt\":pandas_prompt,\n",
    "        \"llm1\":llm,\n",
    "        \"pandas_output_parser\":pandas_output_parser,\n",
    "        \"response_synthesis_prompt\":response_synthesis_prompt,\n",
    "        \"llm2\":llm\n",
    "    },\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "qp.add_chain([\"input\",\"pandas_prompt\",\"llm1\",\"pandas_output_parser\"])\n",
    "qp.add_links(\n",
    "    [\n",
    "        Link(\"input\",\"response_synthesis_prompt\",dest_key=\"query_str\"),\n",
    "        Link(\"llm1\",\"response_synthesis_prompt\",dest_key=\"pandas_instructions\"),\n",
    "        Link(\"pandas_output_parser\",\"response_synthesis_prompt\",dest_key=\"pandas_ouput\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "qp.add_link(\"response_synthesis_prompt\",\"llm2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: qual e o vendedor com maior volume de vendas?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: qual e o vendedor com maior volume de vendas?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: Você está trabalhando com um dataframe do pandas em Python chamado `df_vendas`.\n",
      "('detalhes da colunas do dataframe:\\n', 'ID_compra: object\\nfilial: object\\ncidade: object\\ntipo_cliente: object\\ngenero...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df_vendas.groupby('filial')['total'].sum().idxmax()\n",
      "\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/home/lucas/Área de Trabalho/llm_curso/.venv/lib/python3.12/site-packages/llama_index/experimental/query_engine/pandas/output_parser.py\", line 63, in default_output_processor\n",
      "    output_str = str(safe_eval(module_end_str, global_vars, local_vars))\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/lucas/Área de Trabalho/llm_curso/.venv/lib/python3.12/site-packages/llama_index/experimental/exec_utils.py\", line 159, in safe_eval\n",
      "    return eval(__source, _get_restricted_globals(__globals), __locals)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"<string>\", line 1, in <module>\n",
      "NameError: name 'df_vendas' is not defined\n"
     ]
    }
   ],
   "source": [
    "response = qp.run(query_str=\"qual e o vendedor com maior volume de vendas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There was an error running the output as Python code. Error message: name 'df_vendas' is not defined\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "\n",
    "texto = response\n",
    "\n",
    "text_formatado = textwrap.fill(texto,width=100)\n",
    "print(text_formatado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline de consulta\n",
    "'''Função para obter uma descrição das colunas do DataFrame'''\n",
    "def descricao_colunas(df):\n",
    "    descricao = '\\n'.join([f\"`{col}`: {str(df[col].dtype)}\" for col in df.columns])\n",
    "    return \"Aqui estão os detalhes das colunas do dataframe:\\n\" + descricao\n",
    "\n",
    "'''Definição de módulos da pipeline'''\n",
    "def pipeline_consulta(df):\n",
    "    instruction_str = (\n",
    "        \"1. Converta a consulta para código Python executável usando Pandas.\\n\"\n",
    "        \"2. A linha final do código deve ser uma expressão Python que possa ser chamada com a função `eval()`.\\n\"\n",
    "        \"3. O código deve representar uma solução para a consulta.\\n\"\n",
    "        \"4. IMPRIMA APENAS A EXPRESSÃO.\\n\"\n",
    "        \"5. Não coloque a expressão entre aspas.\\n\")\n",
    "\n",
    "    pandas_prompt_str = (\n",
    "        \"Você está trabalhando com um dataframe do pandas em Python chamado `df`.\\n\"\n",
    "        \"{colunas_detalhes}\\n\\n\"\n",
    "        \"Este é o resultado de `print(df.head())`:\\n\"\n",
    "        \"{df_str}\\n\\n\"\n",
    "        \"Siga estas instruções:\\n\"\n",
    "        \"{instruction_str}\\n\"\n",
    "        \"Consulta: {query_str}\\n\\n\"\n",
    "        \"Expressão:\"\n",
    ")\n",
    "\n",
    "    response_synthesis_prompt_str = (\n",
    "       \"Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\\n\"\n",
    "       \"Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante.\\n\"\n",
    "       \"Consulta: {query_str}\\n\\n\"\n",
    "       \"Instruções do Pandas (opcional):\\n{pandas_instructions}\\n\\n\"\n",
    "       \"Saída do Pandas: {pandas_output}\\n\\n\"\n",
    "       \"Resposta: \\n\\n\"\n",
    "       \"Ao final, exibir o código usado em para gerar a resposta, no formato: O código utilizado foi `{pandas_instructions}`\"\n",
    "    )\n",
    "\n",
    "    pandas_prompt = PromptTemplate(pandas_prompt_str).partial_format(\n",
    "    instruction_str=instruction_str,\n",
    "    df_str=df.head(5),\n",
    "    colunas_detalhes=descricao_colunas(df)\n",
    ")\n",
    "\n",
    "    pandas_output_parser = PandasInstructionParser(df)\n",
    "    response_synthesis_prompt = PromptTemplate(response_synthesis_prompt_str)\n",
    "\n",
    "    '''Criação do Query Pipeline'''\n",
    "    qp = QP(\n",
    "        modules={\n",
    "            \"input\": InputComponent(),\n",
    "            \"pandas_prompt\": pandas_prompt,\n",
    "            \"llm1\": llm,\n",
    "            \"pandas_output_parser\": pandas_output_parser,\n",
    "            \"response_synthesis_prompt\": response_synthesis_prompt,\n",
    "            \"llm2\": llm,\n",
    "        },\n",
    "        verbose=True,\n",
    "    )\n",
    "    qp.add_chain([\"input\", \"pandas_prompt\", \"llm1\", \"pandas_output_parser\"])\n",
    "    qp.add_links(\n",
    "        [\n",
    "            Link(\"input\", \"response_synthesis_prompt\", dest_key=\"query_str\"),\n",
    "            Link(\"llm1\", \"response_synthesis_prompt\", dest_key=\"pandas_instructions\"),\n",
    "            Link(\"pandas_output_parser\", \"response_synthesis_prompt\", dest_key=\"pandas_output\"),\n",
    "        ]\n",
    "    )\n",
    "    qp.add_link(\"response_synthesis_prompt\", \"llm2\")\n",
    "    return qp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interface com o Gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7860\n",
      "INFO:httpx:HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET http://127.0.0.1:7860/gradio_api/startup-events \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: HEAD http://127.0.0.1:7860/ \"HTTP/1.1 200 OK\"\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: GET https://api.gradio.app/pkg-version \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: qual o produto que mais vendeu?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: qual o produto que mais vendeu?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: Você está trabalhando com um dataframe do pandas em Python chamado `df`.\n",
      "Aqui estão os detalhes das colunas do dataframe:\n",
      "`ID_compra`: object\n",
      "`filial`: object\n",
      "`cidade`: object\n",
      "`tipo_cliente`: object\n",
      "`...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df.groupby('tipo_produto')['quantidade'].sum().idxmax()\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: qual o produto que mais vendeu?\n",
      "pandas_instructions: assistant: df.groupby('tipo_produto')['quantidade'].sum().idxmax()\n",
      "pandas_output: Eletrônicos\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\n",
      "Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module input with input: \n",
      "query_str: wich product have the most sales?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module pandas_prompt with input: \n",
      "query_str: wich product have the most sales?\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm1 with input: \n",
      "messages: Você está trabalhando com um dataframe do pandas em Python chamado `df`.\n",
      "Aqui estão os detalhes das colunas do dataframe:\n",
      "`ID_compra`: object\n",
      "`filial`: object\n",
      "`cidade`: object\n",
      "`tipo_cliente`: object\n",
      "`...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "\u001b[1;3;38;2;155;135;227m> Running module pandas_output_parser with input: \n",
      "input: assistant: df.groupby('tipo_produto')['quantidade'].sum().sort_values(ascending=False).head(1)\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module response_synthesis_prompt with input: \n",
      "query_str: wich product have the most sales?\n",
      "pandas_instructions: assistant: df.groupby('tipo_produto')['quantidade'].sum().sort_values(ascending=False).head(1)\n",
      "pandas_output: tipo_produto\n",
      "Eletrônicos    971\n",
      "Name: quantidade, dtype: int64\n",
      "\n",
      "\u001b[0m\u001b[1;3;38;2;155;135;227m> Running module llm2 with input: \n",
      "messages: Dada uma pergunta de entrada, atue como analista de dados e elabore uma resposta a partir dos resultados da consulta.\n",
      "Responda de forma natural, sem introduções como 'A resposta é:' ou algo semelhante...\n",
      "\n",
      "\u001b[0mINFO:httpx:HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://api.groq.com/openai/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "Keyboard interruption in main thread... closing server.\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "def load_data(file_path, df_state):\n",
    "    if file_path is None or file_path == \"\":\n",
    "        return \"Faça o upload de um dataset para começar a análise\", df_state\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        return \"Arquivo carregado com sucesso!\", df\n",
    "    except Exception as e:\n",
    "        return f\"Erro ao carregar o dataset: {str(e)}\", df_state\n",
    "    \n",
    "def proccess_question(question, df_state):\n",
    "    if df_state is not None and question:\n",
    "        qp = pipeline_consulta(df_state)\n",
    "        response = qp.run(query_str=question)\n",
    "        return response.message.content\n",
    "    return \"\"\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    in_file = gr.File(file_count=\"single\",\n",
    "                      type=\"filepath\",\n",
    "                      label=\"Upload CSV\")\n",
    "    status_upload = gr.Textbox(label=\"Status do Upload\")\n",
    "    in_question = gr.Textbox(label=\"Digite sua pergunta sobre os dados\")\n",
    "    bt_submit = gr.Button(\"Enviar\")\n",
    "    out_answer = gr.Textbox(label=\"Resposta\")\n",
    "    df_state = gr.State(value=None)\n",
    "    \n",
    "    in_file.change(fn=load_data,\n",
    "                   inputs=[in_file, df_state],\n",
    "                   outputs=[status_upload, df_state])\n",
    "    \n",
    "    bt_submit.click(fn=proccess_question,\n",
    "                    inputs=[in_question, df_state],\n",
    "                    outputs=out_answer)\n",
    "app.launch(debug=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
